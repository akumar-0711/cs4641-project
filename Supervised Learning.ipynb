{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the setup portion assuming you already have tracks.csv downloaded and the to_write.csv created from Unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA,TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change DATADIR to your directory path to tracks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/Users/harrison/Harrison/CS4641/Project/tracks.csv'\n",
    "#CATEGORIES = [\"Rock\", \"Pop\", \"Jazz\", \"Rap\", \"Hip Hop\", \"EDM\", \"Funk\"]\n",
    "results = []\n",
    "with open(DATADIR) as csvfile:\n",
    "    reader = csv.reader(csvfile)#, quoting=csv.QUOTE_NONNUMERIC) # change contents to floats\n",
    "    for row in reader: # each row is a list\n",
    "        row = np.delete(row, 0,0) # id\n",
    "        row = np.delete(row, 0,0) # name \n",
    "        row = np.delete(row, 0,0) # popularity\n",
    "        row = np.delete(row, 0,0) # duration_ms\n",
    "        row = np.delete(row, 0,0) # explicit\n",
    "        row = np.delete(row, 0,0) # artists\n",
    "        row = np.delete(row, 0,0) # id_artists\n",
    "        row = np.delete(row, 0,0) # release_date\n",
    "        row = np.delete(row, 2,0) # key\n",
    "        row = np.delete(row, 10,0) # time signature\n",
    "        if not row[0] == 'danceability': #ignore the first row of labels\n",
    "            row = row.astype(np.float)\n",
    "            results.append(row)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change DATADIR_2 to your directory path to to_write.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR_2 = '/Users/harrison/Harrison/CS4641/Project/to_write.csv'\n",
    "target = []\n",
    "with open(DATADIR_2) as csvfile2:\n",
    "    reader2 = csv.reader(csvfile2)\n",
    "    for row in reader2:\n",
    "        if not row[0] == 'Cluster':\n",
    "            row = np.array(row)\n",
    "            row = row.astype(np.float)\n",
    "            target.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(results)\n",
    "df_y = pd.DataFrame(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an attempt at Linear Regression. The results are very very poor so we needed to try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x,df_y,test_size=0.2, random_state=4)\n",
    "reg.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03278736368962587"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Linear Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10, whiten='True')\n",
    "x = pca.fit(df_x).transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,df_y,test_size=0.2, random_state=4)\n",
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03278736368962587"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Linear Regression with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 9)\n",
    "x = svd.fit(df_x).transform(df_x)\n",
    "reg = linear_model.LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,df_y,test_size=0.2, random_state=4)\n",
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0257911637694882"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x1 = df_x.iloc[:,1:]\n",
    "df_y1 = df_y.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x1,df_y1,test_size=0.2, random_state=4)\n",
    "rf = RandomForestClassifier(n_estimators = 50)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = y_test.values\n",
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]==s[i]:\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896876464822942"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
